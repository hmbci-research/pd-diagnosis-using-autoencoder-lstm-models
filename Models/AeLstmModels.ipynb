{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpoNycE1O0bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a6a5d8-16cc-455e-dac4-c4b001173deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, BatchNormalization, Flatten, LSTM, Dense,Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "import librosa\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Lnwe2N1cPBda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio_files(data_folder):\n",
        "    audio_signals = []\n",
        "    labels = []\n",
        "    class_folders = os.listdir(data_folder)\n",
        "    for label, class_folder in enumerate(class_folders):\n",
        "        class_path = os.path.join(data_folder, class_folder)\n",
        "        for file_name in os.listdir(class_path):\n",
        "            file_path = os.path.join(class_path, file_name)\n",
        "            signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "            # Normalize the audio signal\n",
        "            min_val = np.min(signal)\n",
        "            max_val = np.max(signal)\n",
        "            signal = (signal - min_val) / (max_val - min_val)\n",
        "\n",
        "            audio_signals.append(signal)\n",
        "            labels.append(label)\n",
        "    return audio_signals, labels\n",
        "\n",
        "train_folder = '/content/drive/My Drive/Audios/Train'\n",
        "validation_folder = '/content/drive/My Drive/Audios/Validation'\n",
        "test_folder = '/content/drive/My Drive/Audios/Test'\n",
        "\n",
        "train_signals, train_labels = load_audio_files(train_folder)\n",
        "validation_signals, validation_labels = load_audio_files(validation_folder)\n",
        "test_signals, test_labels = load_audio_files(test_folder)"
      ],
      "metadata": {
        "id": "9IoyaohUPBgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CAE**"
      ],
      "metadata": {
        "id": "ik24i2wW7v1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(os.listdir(train_folder))\n",
        "\n",
        "#in order the AE to process the signals easily, frame the signals into 25 ms\n",
        "frame_length = 400 #25 window size\n",
        "train_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in train_signals]\n",
        "val_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in validation_signals]\n",
        "test_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in test_signals]\n",
        "\n",
        "#Flatten frames for autoencoder\n",
        "flat_X_train = np.concatenate(train_frames, axis=0)\n",
        "flat_X_val = np.concatenate(val_frames, axis=0)\n",
        "flat_X_test = np.concatenate(test_frames, axis=0)\n",
        "\n",
        "y_train=train_labels\n",
        "y_val=validation_labels\n",
        "y_test=test_labels"
      ],
      "metadata": {
        "id": "ORcBy7rO70Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for Conv1D input (add channel dimension)\n",
        "from tensorflow.keras.layers import UpSampling1D\n",
        "flat_X_train_reshaped = flat_X_train.reshape((flat_X_train.shape[0], flat_X_train.shape[1], 1))\n",
        "flat_X_val_reshaped = flat_X_val.reshape((flat_X_val.shape[0], flat_X_val.shape[1], 1))\n",
        "flat_X_test_reshaped = flat_X_test.reshape((flat_X_test.shape[0], flat_X_test.shape[1], 1))\n",
        "\n",
        "# Define input shape based on reshaped data\n",
        "input_shape = (flat_X_train_reshaped.shape[1], flat_X_train_reshaped.shape[2])\n",
        "\n",
        "# Define Convolutional Autoencoder model\n",
        "inputs = Input(shape=input_shape)\n",
        "x = Conv1D(32, 3, activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "\n",
        "# Latent space\n",
        "encoded = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv1D(64, 3, activation='relu', padding='same')(encoded)\n",
        "x = UpSampling1D(2)(x)\n",
        "x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "decoded = Conv1D(1, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(inputs, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "autoencoder.summary()\n",
        "\n",
        "# Train the autoencoder\n",
        "history = autoencoder.fit(flat_X_train_reshaped, flat_X_train_reshaped,\n",
        "                          epochs=100, batch_size=32,\n",
        "                          validation_data=(flat_X_val_reshaped, flat_X_val_reshaped),\n",
        "                          verbose=1)"
      ],
      "metadata": {
        "id": "mB77XBS-8B6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(inputs, encoded)"
      ],
      "metadata": {
        "id": "7-MpyaxGMNkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "autoencoder.save('/content/drive/My Drive/Results/Models/Cae.h5')\n",
        "encoder.save('/content/drive/My Drive/Results/Models/CaeEncoder.h5')\n",
        "encoded_X_train=encoder.predict(flat_X_train_reshaped)\n",
        "encoded_X_val=encoder.predict(flat_X_val_reshaped)\n",
        "encoded_X_test=encoder.predict(flat_X_test_reshaped)"
      ],
      "metadata": {
        "id": "rYbjIHKz5AKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the encoded signals\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/Results/Models/CaeTrainEncoded.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_train, y_train), f)\n",
        "with open('/content/drive/My Drive/Results/Models/CaeValEncoded.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_val, y_val), f)\n",
        "with open('/content/drive/My Drive/Results/Models/CaeTestEncoded.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_test, y_test), f)"
      ],
      "metadata": {
        "id": "QycvyhblAig8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_shape=(int(encoded_X_train.shape[0]/20), 20, encoded_X_train.shape[1], encoded_X_train.shape[2])\n",
        "new_val_shape=(int(encoded_X_val.shape[0]/20), 20, encoded_X_val.shape[1], encoded_X_val.shape[2])\n",
        "new_test_shape=(int(encoded_X_test.shape[0]/20), 20, encoded_X_test.shape[1], encoded_X_test.shape[2])\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_train = np.zeros(new_train_shape)\n",
        "# Reshape using for loops\n",
        "for i in range(new_train_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(new_train_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * new_train_shape[1] + j\n",
        "        reshaped_train[i, j] = encoded_X_train[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_train.shape)\n",
        "\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_val = np.zeros(new_val_shape)\n",
        "# Reshape using for loops\n",
        "for i in range(new_val_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(new_val_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * new_val_shape[1] + j\n",
        "        reshaped_val[i, j] = encoded_X_val[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_val.shape)\n",
        "\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_test = np.zeros(new_test_shape)\n",
        "# Reshape using for loops\n",
        "for i in range(new_test_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(new_test_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * new_test_shape[1] + j\n",
        "        reshaped_test[i, j] = encoded_X_test[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_test.shape)"
      ],
      "metadata": {
        "id": "1gyX-uA8W0KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape the arrays\n",
        "from tensorflow.keras.layers import Reshape\n",
        "reshape_output1 = Reshape((20,100*128))(reshaped_train)\n",
        "x_tr=np.array(reshape_output1)\n",
        "\n",
        "reshape_output2 = Reshape((20,100*128))(reshaped_val)\n",
        "x_ts=np.array(reshape_output2)\n",
        "\n",
        "reshape_output3 = Reshape((20,100*128))(reshaped_test)\n",
        "x_vl=np.array(reshape_output3)"
      ],
      "metadata": {
        "id": "NQi2VIHFD2Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform labels to numpy array\n",
        "y_train_np = np.array(y_train)\n",
        "y_val_np = np.array(y_val)\n",
        "y_test_np = np.array(y_test)"
      ],
      "metadata": {
        "id": "Xw-23gAxFS_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import LSTM, Dense,Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data_folder = '/content/drive/My Drive/Audios/Train'\n",
        "classes = sorted(os.listdir(data_folder))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_tr, y_train_np, epochs=50, batch_size=32, validation_data=(x_ts, y_val_np))\n",
        "\n",
        "loss, accuracy = model.evaluate(x_vl, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(x_vl)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZGMkxSfWGXBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classification with 1 LSTM block\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_tr.shape[1], x_tr.shape[2]), return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_tr, y_train_np, epochs=50, batch_size=32, validation_data=(x_ts, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(x_vl, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(x_vl)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UKU8p39dGXr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification with 2 LSTM blocks\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_tr.shape[1], x_tr.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_tr, y_train_np, epochs=50, batch_size=32, validation_data=(x_ts, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(x_vl, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(x_vl)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Lass graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OTw2zQpiFEiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification with 3 LSTM blocks\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_tr.shape[1], x_tr.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_tr, y_train_np, epochs=50, batch_size=32, validation_data=(x_ts, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(x_vl, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(x_vl)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JXwRKrOQGTYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SAE**"
      ],
      "metadata": {
        "id": "wHTebtU6MF31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import LSTM, Dense,Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "classes = sorted(os.listdir(train_folder))\n",
        "\n",
        "# In order the AE to process the signals easily, frame the signals into 25 ms\n",
        "frame_length = 400 #25 ms window size\n",
        "train_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in train_signals]\n",
        "val_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in validation_signals]\n",
        "test_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in test_signals]\n",
        "\n",
        "# Flatten frames for autoencoder\n",
        "flat_X_train = np.concatenate(train_frames, axis=0)\n",
        "flat_X_val = np.concatenate(val_frames, axis=0)\n",
        "flat_X_test = np.concatenate(test_frames, axis=0)\n",
        "\n",
        "y_train=train_labels\n",
        "y_val=validation_labels\n",
        "y_test=test_labels\n",
        "\n",
        "# Define the autoencoder\n",
        "input_dim = flat_X_train.shape[1]\n",
        "latent_dim = 64\n",
        "\n",
        "inputs = Input(shape=(input_dim,))\n",
        "encoded = Dense(256, activation='relu')(inputs)\n",
        "encoded = Dense(128, activation='relu')(encoded)\n",
        "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(128, activation='relu')(encoded)\n",
        "decoded = Dense(256, activation='relu')(decoded)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "autoencoder = Model(inputs, decoded)\n",
        "encoder = Model(inputs, encoded)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(flat_X_train, flat_X_train, epochs=100, batch_size=32, shuffle=True, validation_data=(flat_X_val, flat_X_val))\n",
        "\n",
        "encoder = Model(inputs, encoded)\n",
        "# Save the model\n",
        "autoencoder.save('/content/drive/My Drive/Results/Models/Sae.h5')\n",
        "encoder.save('/content/drive/My Drive/Results/Models/SaeEncoder.h5')"
      ],
      "metadata": {
        "id": "WQVWDmHpMJ7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_X_train=encoder.predict(flat_X_train)\n",
        "encoded_X_val=encoder.predict(flat_X_val)\n",
        "encoded_X_test=encoder.predict(flat_X_test)\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/Results/Models/SaeTrainEncoded.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_train, y_train), f)\n",
        "with open('/content/drive/My Drive/Results/Models/SaeValEncoded.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_val, y_val), f)\n",
        "with open('/content/drive/My Drive/Results/Models/SaeTestEncoded.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_test, y_test), f)\n"
      ],
      "metadata": {
        "id": "nDddHi48M1cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_X_train.shape\n",
        "encoded_X_val.shape\n",
        "encoded_X_test.shape"
      ],
      "metadata": {
        "id": "zWfvokqdgsVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_shape=(int(encoded_X_train.shape[0]/20), 20, encoded_X_train.shape[1])\n",
        "new_val_shape=(int(encoded_X_val.shape[0]/20), 20, encoded_X_val.shape[1])\n",
        "new_test_shape=(int(encoded_X_test.shape[0]/20), 20, encoded_X_test.shape[1])\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_train = np.zeros(new_train_shape)\n",
        "\n",
        "# Reshape using for loops\n",
        "for i in range(new_train_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(new_train_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * new_train_shape[1] + j\n",
        "        reshaped_train[i, j] = encoded_X_train[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_train.shape)\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_val = np.zeros(new_val_shape)\n",
        "\n",
        "# Reshape using for loops\n",
        "for i in range(new_val_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(new_val_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * new_val_shape[1] + j\n",
        "        reshaped_val[i, j] = encoded_X_val[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_val.shape)\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_test = np.zeros(new_test_shape)\n",
        "\n",
        "# Reshape using for loops\n",
        "for i in range(new_test_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(new_test_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * new_test_shape[1] + j\n",
        "        reshaped_test[i, j] = encoded_X_test[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_test.shape)"
      ],
      "metadata": {
        "id": "5ULfFvqoNPzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calssification with 0 LSTM\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4xmLbEZ0Uz5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calssification with 1 LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(reshaped_val.shape[1], reshaped_val.shape[2]), return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_3MiT6SxT5y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calssification with 2 LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(reshaped_val.shape[1], reshaped_val.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wg_cxFoKMR8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calssification with 3 LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(reshaped_val.shape[1], reshaped_val.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B9X4AYkOThhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAE**"
      ],
      "metadata": {
        "id": "tWN2Bip4hjH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(os.listdir(train_folder))"
      ],
      "metadata": {
        "id": "6Hc7V9RD9XlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(os.listdir(train_folder))\n",
        "\n",
        "#in order the AE to process the signals easily, frame the signals into 25 ms\n",
        "frame_length = 400 #25 ms window size\n",
        "train_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in train_signals]\n",
        "val_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in validation_signals]\n",
        "test_frames = [librosa.util.frame(signal, frame_length=frame_length, hop_length=frame_length).T for signal in test_signals]\n",
        "\n",
        "#Flatten frames for autoencoder\n",
        "flat_X_train = np.concatenate(train_frames, axis=0)\n",
        "flat_X_val = np.concatenate(val_frames, axis=0)\n",
        "flat_X_test = np.concatenate(test_frames, axis=0)\n",
        "\n",
        "y_train=train_labels\n",
        "y_val=validation_labels\n",
        "y_test=test_labels"
      ],
      "metadata": {
        "id": "dlvzO3VU9uhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for Conv1D input (add channel dimension)\n",
        "from tensorflow.keras.layers import UpSampling1D\n",
        "flat_X_train_reshaped = flat_X_train.reshape((flat_X_train.shape[0], flat_X_train.shape[1], 1))\n",
        "flat_X_val_reshaped = flat_X_val.reshape((flat_X_val.shape[0], flat_X_val.shape[1], 1))\n",
        "flat_X_test_reshaped = flat_X_test.reshape((flat_X_test.shape[0], flat_X_test.shape[1], 1))\n",
        "\n",
        "# Define input shape based on reshaped data\n",
        "input_shape = (flat_X_train_reshaped.shape[1], flat_X_train_reshaped.shape[2]) # (sequence_length, num_features)"
      ],
      "metadata": {
        "id": "NjNTHqgr9y9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Dropout, Input, RepeatVector\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "latent_dim = 32\n",
        "\n",
        "# Encoder\n",
        "inputs = Input(shape=input_shape)\n",
        "encoded = LSTM(128, return_sequences=True, implementation=2)(inputs)\n",
        "encoded = Dropout(0.2)(encoded)\n",
        "encoded = LSTM(64, return_sequences=False, implementation=2)(encoded)  # Return sequences=False for Dense layer\n",
        "encoded = Dropout(0.2)(encoded)\n",
        "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
        "\n",
        "# Decoder\n",
        "decoded = RepeatVector(input_shape[0])(encoded)  # Repeat to match the sequence length\n",
        "decoded = LSTM(64, return_sequences=True, implementation=2)(decoded)\n",
        "decoded = Dropout(0.2)(decoded)\n",
        "decoded = LSTM(128, return_sequences=True, implementation=2)(decoded)\n",
        "decoded = Dropout(0.2)(decoded)\n",
        "decoded = TimeDistributed(Dense(input_shape[1]))(decoded)  # Adjusted to match the number of features\n",
        "\n",
        "# Models\n",
        "autoencoder = Model(inputs, decoded)\n",
        "encoder = Model(inputs, encoded)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer=Adam(), loss='mse')\n",
        "\n",
        "# Ensure you are using a GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "autoencoder.fit(flat_X_train_reshaped, flat_X_train_reshaped, batch_size=batch_size, epochs=epochs, validation_data=(flat_X_val_reshaped,flat_X_val_reshaped))"
      ],
      "metadata": {
        "id": "5BiFUWg6_UHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.save('/content/drive/My Drive/Results/Models/Rae.h5')\n",
        "\n",
        "\n",
        "encoded_X_train = [encoder.predict(flat_X_train_reshaped)]\n",
        "encoded_X_val = [encoder.predict(flat_X_val_reshaped)]\n",
        "encoded_X_test = [encoder.predict(flat_X_test_reshaped)]\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/tezSonrasi/RAEtrain23082024.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_train, y_train), f)\n",
        "with open('/content/drive/My Drive/tezSonrasi/RAEval23082024.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_val, y_val), f)\n",
        "with open('/content/drive/My Drive/tezSonrasi/RAEtest23082024.pkl', 'wb') as f:\n",
        "    pickle.dump((encoded_X_test, y_test), f)"
      ],
      "metadata": {
        "id": "6zkWFAvOLTF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder =Model(inputs, encoded)\n",
        "\n",
        "encoder.save('/content/drive/My Drive/Results/Models/RaeEncoder.h5')"
      ],
      "metadata": {
        "id": "_8YFNEWWHL4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoded_X_train/val/test has 1 item in the list, so take the first and only element's shape\n",
        "encoded_X_train[0].shape"
      ],
      "metadata": {
        "id": "y6tC5WuQdOn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_X_val[0].shape"
      ],
      "metadata": {
        "id": "KEU9pHUYdpLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoded_X_test[0].shape"
      ],
      "metadata": {
        "id": "S18JqxTcduy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_X_train_np=np.array(encoded_X_train[0])\n",
        "encoded_X_val_np=np.array(encoded_X_val[0])\n",
        "encoded_X_test_np=np.array(encoded_X_test[0])"
      ],
      "metadata": {
        "id": "UpelD2WSeRKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_new_shape = (int((encoded_X_train[0].shape[0])/20),20,encoded_X_train[0].shape[1])\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_train = np.zeros(train_new_shape)\n",
        "\n",
        "# Reshape using for loops\n",
        "for i in range(train_new_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(train_new_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * train_new_shape[1] + j\n",
        "        reshaped_train[i, j] = encoded_X_train_np[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_train.shape)\n",
        "\n",
        "val_new_shape = (int((encoded_X_val[0].shape[0])/20),20,encoded_X_val[0].shape[1])\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_val = np.zeros(val_new_shape)\n",
        "\n",
        "# Reshape using for loops\n",
        "for i in range(val_new_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(val_new_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * val_new_shape[1] + j\n",
        "        reshaped_val[i, j] = encoded_X_val_np[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_val.shape)\n",
        "\n",
        "test_new_shape = (int((encoded_X_test[0].shape[0])/20),20,encoded_X_test[0].shape[1])\n",
        "\n",
        "# Initialize the new array with the target shape\n",
        "reshaped_test = np.zeros(test_new_shape)\n",
        "\n",
        "# Reshape using for loops\n",
        "for i in range(test_new_shape[0]):  # Loop over the first dimension ()\n",
        "    for j in range(test_new_shape[1]):  # Loop over the second dimension (20)\n",
        "        # Calculate the corresponding index in the original array\n",
        "        index = i * test_new_shape[1] + j\n",
        "        reshaped_test[i, j] = encoded_X_test_np[index]\n",
        "\n",
        "# Verify the shape\n",
        "print(reshaped_test.shape)"
      ],
      "metadata": {
        "id": "8RJgCqi5dUla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_np=np.array(y_train)\n",
        "y_val_np=np.array(y_val)\n",
        "y_test_np=np.array(y_test)"
      ],
      "metadata": {
        "id": "FCRl7c40jDRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification with 0 LSTM\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uKWocFRHCKwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification with 1 LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(reshaped_val.shape[1], reshaped_val.shape[2]), return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "shKY4F-0krl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification with 2 LSTM\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import LSTM, Dense,Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(reshaped_val.shape[1], reshaped_val.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3e5kGxlKi5ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification with 3 LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(reshaped_val.shape[1], reshaped_val.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128,return_sequences=False))\n",
        "\n",
        "# Fully connected layer with 256 units\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "# Fully connected layer with 64 units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_train, y_train_np, epochs=50, batch_size=32, validation_data=(reshaped_val, y_val_np), callbacks=[EarlyStopping(monitor='val_loss', patience=7)])\n",
        "\n",
        "loss, accuracy = model.evaluate(reshaped_test, y_test_np)\n",
        "# Predictions and confusion matrix\n",
        "y_pred_prob = model.predict(reshaped_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(y_test_np, y_pred)\n",
        "recall = recall_score(y_test_np, y_pred)\n",
        "f1 = f1_score(y_test_np, y_pred)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_np, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_np, y_pred, target_names=classes))\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#loss grafiği\n",
        "# Plot training and validation accuracy curves\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lgZz7QuKknLA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}